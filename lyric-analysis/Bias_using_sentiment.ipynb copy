{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "ATcD69hlMNS_",
    "outputId": "381b9c6c-edb9-400a-d23c-4f6bfa9d27d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.14.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.0.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n",
      "Collecting senticnet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/64/aede8d314be620c67e4c66924e87e8fe068a1373acdbc85aa9399024e6de/senticnet-1.3.tar.gz (51.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 51.5MB 714kB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: senticnet\n",
      "  Running setup.py bdist_wheel for senticnet ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6c/31/73/09a9d3ad453a8d17f8b6f101bafd048de1836707d240432c40\n",
      "Successfully built senticnet\n",
      "Installing collected packages: senticnet\n",
      "Successfully installed senticnet-1.3\n",
      "Collecting afinn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 3.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: afinn\n",
      "  Running setup.py bdist_wheel for afinn ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n",
      "Collecting twython\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/2b/c0883f05b03a8e87787d56395d6c89515fe7e0bf80abd3778b6bb3a6873f/twython-3.7.0.tar.gz\n",
      "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from twython) (2.18.4)\n",
      "Requirement already satisfied: requests_oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from twython) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2.6)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from requests_oauthlib>=0.4.0->twython) (2.1.0)\n",
      "Building wheels for collected packages: twython\n",
      "  Running setup.py bdist_wheel for twython ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c2/b0/a3/5c4b4b87b8c9e4d99f1494a0b471f0134a74e5fb33d426d009\n",
      "Successfully built twython\n",
      "Installing collected packages: twython\n",
      "Successfully installed twython-3.7.0\n",
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 19.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.11.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Running setup.py bdist_wheel for langdetect ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.7\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data] Error loading senticnet: Package 'senticnet' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Error loading demo_liu_hu_lexicon: Package\n",
      "[nltk_data]     'demo_liu_hu_lexicon' not found in index\n",
      "[nltk_data] Error loading SentimentIntensityAnalyzer: Package\n",
      "[nltk_data]     'SentimentIntensityAnalyzer' not found in index\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install senticnet\n",
    "!pip install afinn\n",
    "!pip install twython\n",
    "!pip install langdetect\n",
    "# !pip install cPickle\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('senticnet')\n",
    "nltk.download('demo_liu_hu_lexicon')\n",
    "nltk.download('SentimentIntensityAnalyzer')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJtlrCH6WDYL"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import treebank\n",
    "from nltk import bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8228aZDiatZ"
   },
   "outputs": [],
   "source": [
    "from senticnet.senticnet import SenticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C09WadHXUf3v"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XniQA3tUP0w"
   },
   "source": [
    "Loading all sentiment based lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VUADzL6MLfp"
   },
   "outputs": [],
   "source": [
    "import senticnet\n",
    "from afinn import Afinn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.sentiment.util import demo_liu_hu_lexicon\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "# import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aj-D_PmFVdXA"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQnbhNVuQpY3"
   },
   "outputs": [],
   "source": [
    "# HI Lex\n",
    "with open('HI_POS_dict.json', 'r') as f:\n",
    "    pos_hi_dict = json.load(f)\n",
    "with open('HI_NEG_dict.json', 'r') as f:\n",
    "    neg_hi_dict = json.load(f)\n",
    "\n",
    "# EmoSentiNet\n",
    "with open('ESN_anger_dict.json', 'r') as f:\n",
    "    esn_anger_dict = json.load(f)\n",
    "with open('ESN_sadness_dict.json', 'r') as f:\n",
    "    esn_sad_dict = json.load(f)\n",
    "with open('ESN_joy_dict.json', 'r') as f:\n",
    "    esn_joy_dict = json.load(f)\n",
    "# with open('ESN_surprise_dict.json', 'r') as f:\n",
    "#     esn_surprise_dict = json.load(f)\n",
    "with open('ESN_disgust_dict.json', 'r') as f:\n",
    "    esn_disgust_dict = json.load(f)\n",
    "with open('ESN_fear_dict.json', 'r') as f:\n",
    "    esn_fear_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "347qmy68g_Jo"
   },
   "outputs": [],
   "source": [
    "def clean_dict(dict):\n",
    "  temp = {}\n",
    "  for k,v in dict.items():\n",
    "    cleaned = k.split('#')[0]\n",
    "    temp[cleaned] = v\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qi4b_SrehmLU"
   },
   "outputs": [],
   "source": [
    "pos_hi_dict = clean_dict(pos_hi_dict)\n",
    "neg_hi_dict = clean_dict(neg_hi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvpjvYvygll6"
   },
   "outputs": [],
   "source": [
    "def esn(s):\n",
    "\tbg = bigrams(s)\n",
    "\ttg = trigrams(s)\n",
    "\tscore_esn_sad = 0\n",
    "\tscore_esn_joy = 0\n",
    "\tscore_esn_anger = 0\n",
    "\tscore_esn_disgust = 0\n",
    "\tscore_esn_fear = 0\n",
    "\tfor b,t in zip(bg, tg):\n",
    "\t\tstring1 = b[0] + \" \" + b[1]\n",
    "\t\tstring2 = t[0] + \" \" + t[1] + \" \" + t[2]\n",
    "\t\tif string1 in esn_anger_dict.keys():\n",
    "\t\t\tscore_esn_anger += 1\n",
    "\t\tif string2 in esn_anger_dict.keys():\n",
    "\t\t\tscore_esn_anger += 1\n",
    "\t\t\n",
    "\t\tif string1 in esn_disgust_dict.keys():\n",
    "\t\t\tscore_esn_disgust += 1\n",
    "\t\tif string2 in esn_disgust_dict.keys():\n",
    "\t\t\tscore_esn_disgust += 1\n",
    "\t\t\n",
    "\t\tif string1 in esn_sad_dict.keys():\n",
    "\t\t\tscore_esn_sad += 1\n",
    "\t\tif string2 in esn_sad_dict.keys():\n",
    "\t\t\tscore_esn_sad += 1\n",
    "\n",
    "\t\tif string1 in esn_joy_dict.keys():\n",
    "\t\t\tscore_esn_joy += 1\n",
    "\t\tif string2 in esn_joy_dict.keys():\n",
    "\t\t\tscore_esn_joy += 1\n",
    "\n",
    "\t\tif string1 in esn_fear_dict.keys():\n",
    "\t\t\tscore_esn_fear += 1\n",
    "\t\tif string2 in esn_fear_dict.keys():\n",
    "\t\t\tscore_esn_fear += 1\n",
    "\treturn (score_esn_anger, score_esn_disgust, score_esn_sad, score_esn_joy, score_esn_fear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUbl7ed3glfE"
   },
   "outputs": [],
   "source": [
    "def liu_hu_lexicon(sentence):\n",
    "    \"\"\"\n",
    "    Basic example of sentiment classification using Liu and Hu opinion lexicon.\n",
    "    This function simply counts the number of positive, negative and neutral words\n",
    "    in the sentence and classifies it depending on which polarity is more represented.\n",
    "    Words that do not appear in the lexicon are considered as neutral.\n",
    "    :param sentence: a sentence whose polarity has to be classified.\n",
    "    \"\"\"\n",
    "    from nltk.corpus import opinion_lexicon\n",
    "    from nltk.tokenize import treebank\n",
    "\n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    pos_words = 0\n",
    "    neg_words = 0\n",
    "    tokenized_sent = [word.lower() for word in tokenizer.tokenize(sentence)]\n",
    "\n",
    "    for word in tokenized_sent:\n",
    "        if word in opinion_lexicon.positive():\n",
    "            pos_words += 1\n",
    "        elif word in opinion_lexicon.negative():\n",
    "            neg_words += 1\n",
    "\n",
    "\n",
    "    if pos_words > neg_words:\n",
    "        return 1 # positive\n",
    "    elif pos_words < neg_words:\n",
    "        return -1 # negative\n",
    "    elif pos_words == neg_words:\n",
    "        return 0 # neutral\n",
    "\n",
    "    return np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nErrmFxTygf"
   },
   "outputs": [],
   "source": [
    "filename = \"/content/gdrive/My Drive/lyrics.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opv2uSTlU_Ck"
   },
   "outputs": [],
   "source": [
    "df = df[df['lyrics']!='instrumental'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7s6etOWoU_vv"
   },
   "outputs": [],
   "source": [
    "genres = df.genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPnc13fdV-3m"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9LVGThVVwfg"
   },
   "outputs": [],
   "source": [
    "lyrics = df['lyrics']\n",
    "vocab = set()\n",
    "for lyric in lyrics:\n",
    "  words = lyric.split()\n",
    "  for word in words:\n",
    "    vocab.add(lemmatizer.lemmatize(word.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9JUmkVFZVwWw",
    "outputId": "0390630d-c46e-473b-ef99-3a1d02db8a22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837079"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lb6_6g2cVBzl"
   },
   "outputs": [],
   "source": [
    "def get_contexts_with_word(df2,word):\n",
    "#   df2 = df.sample(100)\n",
    "#   df2 = df2.dropna()\n",
    "#   df2['lyrics'] = df2['lyrics'].replace(r'\\n', ' ', regex = True)\n",
    "  r = []\n",
    "  ind = 0\n",
    "  indices = []\n",
    "  \n",
    "  for i,row in df2.iterrows():\n",
    "#     print(row)      \n",
    "      l = row['lyrics']\n",
    "      if (any(c.isalpha() for c in l) and detect(l) == 'en'):\n",
    "          r.append(l.split())\n",
    "          indices.append(row['index'])\n",
    "      ind += 1\n",
    "\n",
    "\n",
    "  k = 15\n",
    "  she_phrases = []\n",
    "  she_ind = []\n",
    "  for i,v in enumerate(r):\n",
    "    for ngram in nltk.ngrams(v, 2*k+1, pad_left=True, pad_right=True, left_pad_symbol=\" \", right_pad_symbol = \" \"):\n",
    "      if ngram[k].lower() == word:\n",
    "          s = \" \".join(ngram)\n",
    "#           print('s', s)\n",
    "          she_phrases.append((indices[i],s))\n",
    "#           she_ind.append(indices)\n",
    "          \n",
    "  return (she_phrases,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Czmbc5zf4tJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KVovkeiZ696"
   },
   "outputs": [],
   "source": [
    "woman_insults = pd.read_csv('woman_insults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G51g56tAcaFS"
   },
   "outputs": [],
   "source": [
    "w_insults = woman_insults['insults'].tolist()\n",
    "for i in range(len(w_insults)):\n",
    "  w_insults[i] = w_insults[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mdv8B_Sad-Qz"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_lko_s2d_LW"
   },
   "outputs": [],
   "source": [
    "def get_sentiment_word_context(df2,contextp,word):\n",
    "  for loc,context in contextp:\n",
    "    context = context\n",
    "    score_sn = 0\n",
    "    score_swn_pos = 0\n",
    "    sn = SenticNet()\n",
    "    score_swn_neg = 0\n",
    "    count_swn = 0\n",
    "    score_hi_pos = 0\n",
    "    score_hi_neg = 0\n",
    "#     print(context)\n",
    "    for word in context.split():\n",
    "      # Sentic Net\n",
    "      try:\n",
    "        sentics = sn.sentics(word)\n",
    "        score_sn_sensitivity = abs(float(sentics['sensitivity']))\n",
    "        score_sn_pleasantness = float(sentics['pleasantness'])\n",
    "      except:\n",
    "        score_sn_sensitivity = 0\n",
    "        score_sn_pleasantness = 0\n",
    "  #     Sentic Word Net\n",
    "      word_swn_lemmas = wn.synsets(word)\n",
    "      if not not word_swn_lemmas:\n",
    "        ans = swn.senti_synset(word_swn_lemmas[0].name()) #using 0 index because\n",
    "        score_swn_pos += ans.pos_score()\n",
    "        score_swn_neg += ans.neg_score()\n",
    "        count_swn += 1\n",
    "      # HI Score\n",
    "      if word in pos_hi_dict.keys():\n",
    "        score_hi_pos += pos_hi_dict[word]\n",
    "      if word in neg_hi_dict.keys():\n",
    "        score_hi_neg += neg_hi_dict[word]\n",
    "\n",
    "    (score_esn_anger, score_esn_disgust, score_esn_sad, score_esn_joy, score_esn_fear) = esn(context)\n",
    "#     print(score_esn_anger, score_esn_disgust, score_esn_sad, score_esn_joy, score_esn_fear)\n",
    "    df2.at[loc,'score_esn_anger'] += score_esn_anger\n",
    "    df2.at[loc,'score_esn_sad'] += score_esn_sad\n",
    "    df2.at[loc,'score_esn_joy'] += score_esn_joy\n",
    "    df2.at[loc,'score_esn_fear'] += score_esn_fear\n",
    "    df2.at[loc,'score_esn_disgust'] += score_esn_disgust\n",
    "    df2.at[loc,'score_hi_neg'] += score_hi_neg\n",
    "    df2.at[loc,'score_hi_pos'] += score_hi_pos\n",
    "    df2.at[loc,'score_swn_pos'] += score_swn_pos\n",
    "    df2.at[loc,'score_swn_neg'] += score_swn_neg\n",
    "    df2.at[loc,'score_sn_sensitivity'] += score_sn_sensitivity\n",
    "    df2.at[loc,'score_sn_pleasantness'] += score_sn_pleasantness\n",
    "  return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ql9bxVw6lf4M"
   },
   "outputs": [],
   "source": [
    "def add_cols(df):\n",
    "  sLen = len(df)\n",
    "  df['score_esn_anger'] = 0\n",
    "  df['score_esn_sad'] = 0\n",
    "  df['score_esn_joy'] = 0\n",
    "  df['score_esn_fear'] = 0\n",
    "  df['score_esn_disgust'] = 0\n",
    "  df['score_hi_neg'] = 0\n",
    "  df['score_hi_pos'] = 0\n",
    "  df['score_swn_pos'] = 0\n",
    "  df['score_swn_neg'] = 0\n",
    "  df['score_sn_sensitivity'] = 0\n",
    "  df['score_sn_pleasantness'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQwJnxq6jgsE"
   },
   "outputs": [],
   "source": [
    "she_phrases,index = get_contexts_with_word(df,\"she\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mgKLylnA5Gr"
   },
   "outputs": [],
   "source": [
    "d_female = df.copy()\n",
    "add_cols(d_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUmSWlObA19b"
   },
   "outputs": [],
   "source": [
    "d_female = get_sentiment_word_context(d_female,he_phrases,\"she\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6iawiQRO4mO"
   },
   "outputs": [],
   "source": [
    "df_male = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_H6fvJruG_w"
   },
   "outputs": [],
   "source": [
    "add_cols(df_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONfBM8RluOKW"
   },
   "outputs": [],
   "source": [
    "he_phrases,index = get_contexts_with_word(df,\"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zc5IUI6HuZ9v"
   },
   "outputs": [],
   "source": [
    "d_male = get_sentiment_word_context(df_male,he_phrases,\"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "T8snQGd2w0Nb",
    "outputId": "3d7ec8af-5991-4cc6-df81-0d6726fa4aee"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fa9e36ed8eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_male\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'he_sentiment.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at line 230650"
     ]
    }
   ],
   "source": [
    "df_male = pd.read_csv('he_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fejwR77EyBge"
   },
   "outputs": [],
   "source": [
    "d_female = pdto_csv('she_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "VZU3su-U1VXz",
    "outputId": "032b6e2c-479a-499c-913e-1279df0bd6b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_esn_anger</th>\n",
       "      <th>score_esn_sad</th>\n",
       "      <th>score_esn_joy</th>\n",
       "      <th>score_esn_fear</th>\n",
       "      <th>score_esn_disgust</th>\n",
       "      <th>score_hi_neg</th>\n",
       "      <th>score_hi_pos</th>\n",
       "      <th>score_swn_pos</th>\n",
       "      <th>score_swn_neg</th>\n",
       "      <th>score_sn_pleasantness</th>\n",
       "      <th>score_sn_sensitivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.025932</td>\n",
       "      <td>1.541365</td>\n",
       "      <td>0.638140</td>\n",
       "      <td>0.283023</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.558543</td>\n",
       "      <td>0.713693</td>\n",
       "      <td>0.302513</td>\n",
       "      <td>0.184045</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663843</td>\n",
       "      <td>1.091841</td>\n",
       "      <td>0.390994</td>\n",
       "      <td>0.210432</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hip-Hop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.039559</td>\n",
       "      <td>2.455270</td>\n",
       "      <td>0.819711</td>\n",
       "      <td>0.498410</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.553509</td>\n",
       "      <td>0.801207</td>\n",
       "      <td>0.290568</td>\n",
       "      <td>0.131788</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jazz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.497616</td>\n",
       "      <td>0.813300</td>\n",
       "      <td>0.339774</td>\n",
       "      <td>0.143664</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.320015</td>\n",
       "      <td>0.316605</td>\n",
       "      <td>0.139357</td>\n",
       "      <td>0.110812</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Available</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.631953</td>\n",
       "      <td>0.904635</td>\n",
       "      <td>0.393957</td>\n",
       "      <td>0.191734</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.569667</td>\n",
       "      <td>0.782232</td>\n",
       "      <td>0.341299</td>\n",
       "      <td>0.148005</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.627895</td>\n",
       "      <td>0.986727</td>\n",
       "      <td>0.434786</td>\n",
       "      <td>0.176648</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.757059</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.420294</td>\n",
       "      <td>0.180882</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.715510</td>\n",
       "      <td>0.986125</td>\n",
       "      <td>0.416633</td>\n",
       "      <td>0.208129</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score_esn_anger  score_esn_sad  score_esn_joy  score_esn_fear  \\\n",
       "genre                                                                          \n",
       "Country                    0.0            0.0            0.0             0.0   \n",
       "Electronic                 0.0            0.0            0.0             0.0   \n",
       "Folk                       0.0            0.0            0.0             0.0   \n",
       "Hip-Hop                    0.0            0.0            0.0             0.0   \n",
       "Indie                      0.0            0.0            0.0             0.0   \n",
       "Jazz                       0.0            0.0            0.0             0.0   \n",
       "Metal                      0.0            0.0            0.0             0.0   \n",
       "Not Available              0.0            0.0            0.0             0.0   \n",
       "Other                      0.0            0.0            0.0             0.0   \n",
       "Pop                        0.0            0.0            0.0             0.0   \n",
       "R&B                        0.0            0.0            0.0             0.0   \n",
       "Rock                       0.0            0.0            0.0             0.0   \n",
       "\n",
       "               score_esn_disgust  score_hi_neg  score_hi_pos  score_swn_pos  \\\n",
       "genre                                                                         \n",
       "Country                      0.0     -1.025932      1.541365       0.638140   \n",
       "Electronic                   0.0     -0.558543      0.713693       0.302513   \n",
       "Folk                         0.0     -0.663843      1.091841       0.390994   \n",
       "Hip-Hop                      0.0     -2.039559      2.455270       0.819711   \n",
       "Indie                        0.0     -0.553509      0.801207       0.290568   \n",
       "Jazz                         0.0     -0.497616      0.813300       0.339774   \n",
       "Metal                        0.0     -0.320015      0.316605       0.139357   \n",
       "Not Available                0.0     -0.631953      0.904635       0.393957   \n",
       "Other                        0.0     -0.569667      0.782232       0.341299   \n",
       "Pop                          0.0     -0.627895      0.986727       0.434786   \n",
       "R&B                          0.0     -0.757059      1.120000       0.420294   \n",
       "Rock                         0.0     -0.715510      0.986125       0.416633   \n",
       "\n",
       "               score_swn_neg  score_sn_pleasantness  score_sn_sensitivity  \n",
       "genre                                                                      \n",
       "Country             0.283023               0.004449              0.000070  \n",
       "Electronic          0.184045               0.001256              0.000000  \n",
       "Folk                0.210432               0.004458              0.000446  \n",
       "Hip-Hop             0.498410               0.003823              0.000080  \n",
       "Indie               0.131788               0.000953              0.000000  \n",
       "Jazz                0.143664               0.001631              0.000000  \n",
       "Metal               0.110812               0.000758              0.000126  \n",
       "Not Available       0.191734               0.002090              0.000000  \n",
       "Other               0.148005               0.002313              0.000000  \n",
       "Pop                 0.176648               0.002546              0.000049  \n",
       "R&B                 0.180882               0.001765              0.000000  \n",
       "Rock                0.208129               0.002390              0.000055  "
      ]
     },
     "execution_count": 188,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_female.groupby(['genre'])[['score_esn_anger','score_esn_sad','score_esn_joy','score_esn_fear','score_esn_disgust','score_hi_neg','score_hi_pos','score_swn_pos','score_swn_neg','score_sn_pleasantness','score_sn_sensitivity']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "ykUMSZEg4WQd",
    "outputId": "4f193f76-9634-450f-8e8e-6e75968e1cda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_esn_anger</th>\n",
       "      <th>score_esn_sad</th>\n",
       "      <th>score_esn_joy</th>\n",
       "      <th>score_esn_fear</th>\n",
       "      <th>score_esn_disgust</th>\n",
       "      <th>score_hi_neg</th>\n",
       "      <th>score_hi_pos</th>\n",
       "      <th>score_swn_pos</th>\n",
       "      <th>score_swn_neg</th>\n",
       "      <th>score_sn_pleasantness</th>\n",
       "      <th>score_sn_sensitivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.817853</td>\n",
       "      <td>1.153017</td>\n",
       "      <td>0.444174</td>\n",
       "      <td>0.210303</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.275377</td>\n",
       "      <td>0.328266</td>\n",
       "      <td>0.144724</td>\n",
       "      <td>0.084799</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.643781</td>\n",
       "      <td>0.798930</td>\n",
       "      <td>0.316095</td>\n",
       "      <td>0.182345</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hip-Hop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.216749</td>\n",
       "      <td>1.324802</td>\n",
       "      <td>0.439575</td>\n",
       "      <td>0.273089</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.348365</td>\n",
       "      <td>0.514131</td>\n",
       "      <td>0.189266</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jazz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.441907</td>\n",
       "      <td>0.763237</td>\n",
       "      <td>0.316060</td>\n",
       "      <td>0.127854</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.371927</td>\n",
       "      <td>0.335088</td>\n",
       "      <td>0.137336</td>\n",
       "      <td>0.133673</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Available</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.478374</td>\n",
       "      <td>0.714739</td>\n",
       "      <td>0.305278</td>\n",
       "      <td>0.141335</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.384853</td>\n",
       "      <td>0.566198</td>\n",
       "      <td>0.223935</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.423762</td>\n",
       "      <td>0.702143</td>\n",
       "      <td>0.318817</td>\n",
       "      <td>0.120047</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.579706</td>\n",
       "      <td>0.884706</td>\n",
       "      <td>0.340882</td>\n",
       "      <td>0.157941</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.483222</td>\n",
       "      <td>0.605466</td>\n",
       "      <td>0.250659</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score_esn_anger  score_esn_sad  score_esn_joy  score_esn_fear  \\\n",
       "genre                                                                          \n",
       "Country                    0.0            0.0            0.0             0.0   \n",
       "Electronic                 0.0            0.0            0.0             0.0   \n",
       "Folk                       0.0            0.0            0.0             0.0   \n",
       "Hip-Hop                    0.0            0.0            0.0             0.0   \n",
       "Indie                      0.0            0.0            0.0             0.0   \n",
       "Jazz                       0.0            0.0            0.0             0.0   \n",
       "Metal                      0.0            0.0            0.0             0.0   \n",
       "Not Available              0.0            0.0            0.0             0.0   \n",
       "Other                      0.0            0.0            0.0             0.0   \n",
       "Pop                        0.0            0.0            0.0             0.0   \n",
       "R&B                        0.0            0.0            0.0             0.0   \n",
       "Rock                       0.0            0.0            0.0             0.0   \n",
       "\n",
       "               score_esn_disgust  score_hi_neg  score_hi_pos  score_swn_pos  \\\n",
       "genre                                                                         \n",
       "Country                      0.0     -0.817853      1.153017       0.444174   \n",
       "Electronic                   0.0     -0.275377      0.328266       0.144724   \n",
       "Folk                         0.0     -0.643781      0.798930       0.316095   \n",
       "Hip-Hop                      0.0     -1.216749      1.324802       0.439575   \n",
       "Indie                        0.0     -0.348365      0.514131       0.189266   \n",
       "Jazz                         0.0     -0.441907      0.763237       0.316060   \n",
       "Metal                        0.0     -0.371927      0.335088       0.137336   \n",
       "Not Available                0.0     -0.478374      0.714739       0.305278   \n",
       "Other                        0.0     -0.384853      0.566198       0.223935   \n",
       "Pop                          0.0     -0.423762      0.702143       0.318817   \n",
       "R&B                          0.0     -0.579706      0.884706       0.340882   \n",
       "Rock                         0.0     -0.483222      0.605466       0.250659   \n",
       "\n",
       "               score_swn_neg  score_sn_pleasantness  score_sn_sensitivity  \n",
       "genre                                                                      \n",
       "Country             0.210303               0.002920              0.000000  \n",
       "Electronic          0.084799               0.000503              0.000000  \n",
       "Folk                0.182345               0.001783              0.000000  \n",
       "Hip-Hop             0.273089               0.001046              0.000040  \n",
       "Indie               0.093045               0.000953              0.000000  \n",
       "Jazz                0.127854               0.003388              0.000000  \n",
       "Metal               0.133673               0.000421              0.000042  \n",
       "Not Available       0.141335               0.001295              0.000042  \n",
       "Other               0.120833               0.003083              0.000000  \n",
       "Pop                 0.120047               0.002818              0.000000  \n",
       "R&B                 0.157941               0.000294              0.000000  \n",
       "Rock                0.138783               0.000879              0.000055  "
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.groupby(['genre'])[['score_esn_anger','score_esn_sad','score_esn_joy','score_esn_fear','score_esn_disgust','score_hi_neg','score_hi_pos','score_swn_pos','score_swn_neg','score_sn_pleasantness','score_sn_sensitivity']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2i3oLzp6IAY"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "colab_type": "code",
    "id": "5nfgUG0v7RnE",
    "outputId": "4b20db99-e865-4914-ed2c-ad0572cafdea"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-32ee554f3b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# create plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mbar_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mopacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFOCAYAAABNFY7/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njBpYUMuoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a371dda0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to plot\n",
    "n_groups = 4\n",
    "means_frank = (90, 55, 40, 65)\n",
    "means_guido = (85, 62, 54, 20)\n",
    " \n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, means_frank, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Frank')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, means_guido, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='Guido')\n",
    " \n",
    "plt.xlabel('Person')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by person')\n",
    "plt.xticks(index + bar_width, ('A', 'B', 'C', 'D'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bias using sentiment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
